{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "orig_data = pd.read_csv(r\"C:\\Users\\Amanda\\Downloads\\datasets_2330_3928_concrete_data.csv\",sep=',')\n",
    "orig_data.head()\n",
    "data = orig_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['cimento', 'escória', 'cinzas', 'água', 'superplastificante', 'ag_grosso', 'ag_fino', 'idade', 'resistência']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[data.columns[:-1]],\n",
    "                                                    data[[data.columns[-1]]],\n",
    "                                                    test_size = .3,\n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padronizando dados\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will save the model performance metrics in a DataFrame\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "Model = []\n",
    "RMSE = []\n",
    "R_sq = []\n",
    "cv = KFold(10, random_state = 1)\n",
    "\n",
    "#Creating a Function to append the cross validation scores of the algorithms\n",
    "def input_scores(name, model, x, y):\n",
    "    Model.append(name)\n",
    "    RMSE.append(np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, \n",
    "                                               scoring='neg_mean_squared_error').mean()))\n",
    "    R_sq.append(cross_val_score(model, x, y, cv=cv, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                              AdaBoostRegressor)\n",
    "\n",
    "names = ['Regressão Linear', 'Regressão Lasso', 'Regressão Ridge ', \n",
    "         'KNN', 'AdaBoost', 'Árvore de decisão', \n",
    "         'Floresta aleatória ', 'Gradiente Boosting'\n",
    "         ]\n",
    "models = [LinearRegression(), Lasso(), Ridge(),\n",
    "          KNeighborsRegressor(), AdaBoostRegressor(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor() \n",
    "          ]\n",
    "\n",
    "#Running all algorithms\n",
    "for name, model in zip(names, models):\n",
    "    input_scores(name, model, x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Linear</td>\n",
       "      <td>10.253646</td>\n",
       "      <td>0.620875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Lasso</td>\n",
       "      <td>10.830778</td>\n",
       "      <td>0.579454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regressão Ridge</td>\n",
       "      <td>10.252755</td>\n",
       "      <td>0.620908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>9.028723</td>\n",
       "      <td>0.705960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>7.589431</td>\n",
       "      <td>0.786656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Árvore de decisão</td>\n",
       "      <td>7.298293</td>\n",
       "      <td>0.813419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Floresta aleatória</td>\n",
       "      <td>5.341337</td>\n",
       "      <td>0.896260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradiente Boosting</td>\n",
       "      <td>5.163711</td>\n",
       "      <td>0.903980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo       RMSE  R Squared\n",
       "0     Regressão Linear  10.253646   0.620875\n",
       "1      Regressão Lasso  10.830778   0.579454\n",
       "2     Regressão Ridge   10.252755   0.620908\n",
       "3                  KNN   9.028723   0.705960\n",
       "4             AdaBoost   7.589431   0.786656\n",
       "5    Árvore de decisão   7.298293   0.813419\n",
       "6  Floresta aleatória    5.341337   0.896260\n",
       "7   Gradiente Boosting   5.163711   0.903980"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame({'Modelo': Model,\n",
    "                           'RMSE': RMSE,\n",
    "                           'R Squared': R_sq})\n",
    "\n",
    "evaluation\n",
    "## Resultado de separação dos dados com validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino e Teste\n",
    "df = pd.read_csv(r\"C:\\Users\\Amanda\\Downloads\\datasets_2330_3928_concrete_data.csv\",sep=',')\n",
    "df.columns = ['cimento', 'escória', 'cinzas', 'água', 'superplastificante', 'ag_grosso', 'ag_fino', 'idade', 'resistência']\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder , LabelEncoder\n",
    "#Colocando os dados em ordem aleatória \n",
    "randomdata = (df.sample(n=1030, replace=False, random_state = 42))\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "X = randomdata.drop('resistência', axis = 1)\n",
    "y = randomdata['resistência']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#Padronizando dados\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Linear:\n",
      "Erro Quadrático Médio: 119.77025860336974\n",
      "Raiz do Erro Quadrático Médio: 10.943959914188728\n",
      "R2: 0.6012677942691227\n",
      "Regressão LASSO:\n",
      "Erro Quadrático Médio: 138.41794877014743\n",
      "Raiz do Erro Quadrático Médio: 11.765115756767862\n",
      "R2: 0.5391869845698769\n",
      "Regressão de Rigde :\n",
      "Erro Quadrático Médio: 119.75975286660149\n",
      "Raiz do Erro Quadrático Médio: 10.943479924895987\n",
      "R2: 0.6013027693592934\n",
      "K vizinhos mais próximos:\n",
      "Erro Quadrático Médio: 84.2553049579288\n",
      "Raiz do Erro Quadrático Médio: 9.179068850266283\n",
      "R2: 0.7195021202913436\n",
      "Regressão AdaBoost:\n",
      "Erro Quadrático Médio: 69.23119671302567\n",
      "Raiz do Erro Quadrático Médio: 8.320528631825365\n",
      "R2: 0.769519510998231\n",
      "Arvores de Decisão:\n",
      "Erro Quadrático Médio: 81.8063303487954\n",
      "Raiz do Erro Quadrático Médio: 9.044685198988155\n",
      "R2: 0.7276551046721522\n",
      "Florestas aleatórias de decisão:\n",
      "Erro Quadrático Médio: 39.156447619043014\n",
      "Raiz do Erro Quadrático Médio: 6.257511295958084\n",
      "R2: 0.8696426232205922\n",
      "Regressão Gradiente Boosting:\n",
      "Erro Quadrático Médio: 41.756096955068664\n",
      "Raiz do Erro Quadrático Médio: 6.461895770984601\n",
      "R2: 0.8609880212687587\n",
      "Raiz do Erro Quadrático Médio: 6.018950291906004\n",
      "R2: 0.8793926316500458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                              AdaBoostRegressor)\n",
    "\n",
    "###Regressao Linear\n",
    "LIR = LinearRegression()\n",
    "LIR = LIR.fit(X_train, y_train)\n",
    "pred_lir = LIR.predict(X_test)\n",
    "print('Regressão Linear:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_lir))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_lir)))\n",
    "print('R2:', r2_score(y_test, pred_lir))\n",
    "lir0 = np.sqrt(mean_squared_error(y_test, pred_lir))\n",
    "lir1 = r2_score(y_test, pred_lir)\n",
    "\n",
    "\n",
    "#Lasso Regression\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "LASSO = Lasso()\n",
    "LASSO = LASSO.fit(X_train, y_train)\n",
    "pred_lasso = LASSO.predict(X_test)\n",
    "print('Regressão LASSO:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_lasso))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_lasso)))\n",
    "print('R2:', r2_score(y_test, pred_lasso))\n",
    "lasso0 = np.sqrt(mean_squared_error(y_test, pred_lasso))\n",
    "lasso1 = r2_score(y_test, pred_lasso)\n",
    "\n",
    "##Regressão de Ridge\n",
    "ridge  = Ridge()\n",
    "ridge  = ridge.fit(X_train, y_train)\n",
    "pred_ridge  = ridge.predict(X_test)\n",
    "print('Regressão de Rigde :')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_ridge))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_ridge)))\n",
    "print('R2:', r2_score(y_test, pred_ridge))\n",
    "ridge0 = np.sqrt(mean_squared_error(y_test, pred_ridge))\n",
    "ridge1 = r2_score(y_test, pred_ridge)\n",
    "\n",
    "###KNN\n",
    "KNN = KNeighborsRegressor()\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_knn = KNN.predict(X_test)\n",
    "print('K vizinhos mais próximos:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_knn))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_knn)))\n",
    "print('R2:', r2_score(y_test, pred_knn))\n",
    "knn0 = np.sqrt(mean_squared_error(y_test, pred_knn))\n",
    "knn1 = r2_score(y_test, pred_knn)\n",
    "\n",
    "#Ada Boost Regressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adb = AdaBoostRegressor()\n",
    "adb = adb.fit(X_train, y_train)\n",
    "pred_adb = adb.predict(X_test)\n",
    "print('Regressão AdaBoost:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_adb))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_adb)))\n",
    "print('R2:', r2_score(y_test, pred_adb))\n",
    "adb0 = np.sqrt(mean_squared_error(y_test, pred_adb))\n",
    "adb1 = r2_score(y_test, pred_adb)\n",
    "\n",
    "\n",
    "###Árvore de decisão\n",
    "DTR = DecisionTreeRegressor(random_state = 42)\n",
    "DTR = DTR.fit(X_train, y_train)\n",
    "pred_dtr = DTR.predict(X_test)\n",
    "print('Arvores de Decisão:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_dtr))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_dtr)))\n",
    "print('R2:', r2_score(y_test, pred_dtr))\n",
    "dtr0 = np.sqrt(mean_squared_error(y_test, pred_dtr))\n",
    "dtr1 = r2_score(y_test, pred_dtr)\n",
    "\n",
    "\n",
    "###Random Forest\n",
    "RFR = RandomForestRegressor(n_estimators=200, random_state = 42)\n",
    "RFR = RFR.fit(X_train, y_train)\n",
    "pred_rfr = RFR.predict(X_test)\n",
    "print('Florestas aleatórias de decisão:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_rfr))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_rfr)))\n",
    "print('R2:', r2_score(y_test, pred_rfr))\n",
    "rfr0 = np.sqrt(mean_squared_error(y_test, pred_rfr))\n",
    "rfr1 = r2_score(y_test, pred_rfr)\n",
    "\n",
    "#Regressão Gradiente Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr = gbr.fit(X_train, y_train)\n",
    "pred_gbr = gbr.predict(X_test)\n",
    "print('Regressão Gradiente Boosting:')\n",
    "print('Erro Quadrático Médio:', mean_squared_error(y_test, pred_gbr))\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, pred_gbr)))\n",
    "print('R2:', r2_score(y_test, pred_gbr))\n",
    "gbr0 = np.sqrt(mean_squared_error(y_test, pred_gbr))\n",
    "gbr1 = r2_score(y_test, pred_gbr)\n",
    "\n",
    "from sklearn import ensemble\n",
    "params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Raiz do Erro Quadrático Médio:', np.sqrt(mean_squared_error(y_test, clf.predict(X_test))))\n",
    "print('R2:', r2_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "\n",
    "conc0 = {\n",
    "    'REQM':[lir0,lasso0,ridge0,knn0,adb0,dtr0,rfr0,gbr0] , 'R2':[lir1,lasso1,ridge1,knn1,adb1,dtr1,rfr1,gbr1]\n",
    "\n",
    "}\n",
    "concl0 = pd.DataFrame(conc0, columns=['REQM', 'R2'], index=['Linear','Lasso','Ridge','KNN','ADB', 'DT', 'RF','Gbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REQM</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>10.943960</td>\n",
       "      <td>0.601268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>11.765116</td>\n",
       "      <td>0.539187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>10.943480</td>\n",
       "      <td>0.601303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>9.179069</td>\n",
       "      <td>0.719502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADB</th>\n",
       "      <td>8.089312</td>\n",
       "      <td>0.782151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>9.044685</td>\n",
       "      <td>0.727655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>6.257511</td>\n",
       "      <td>0.869643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gbr</th>\n",
       "      <td>6.457420</td>\n",
       "      <td>0.861181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             REQM        R2\n",
       "Linear  10.943960  0.601268\n",
       "Lasso   11.765116  0.539187\n",
       "Ridge   10.943480  0.601303\n",
       "KNN      9.179069  0.719502\n",
       "ADB      8.089312  0.782151\n",
       "DT       9.044685  0.727655\n",
       "RF       6.257511  0.869643\n",
       "Gbr      6.457420  0.861181"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concl0\n",
    "## Resultado de separação dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning this base model\n",
    "GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.2, loss='ls', max_depth=10,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=100,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=20,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "R2: -0.24902972008134724\n"
     ]
    }
   ],
   "source": [
    "#tuning for number of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators':range(20,1001,10),\n",
    "              'max_depth':[10], \n",
    "              'min_samples_split':[100],  \n",
    "              'learning_rate':[0.2]}\n",
    "clf = GridSearchCV(GradientBoostingRegressor(random_state=1), \n",
    "                   param_grid = param_grid, scoring='r2', \n",
    "                   cv=cv).fit(x_train_scaled, y_train)\n",
    "print(clf.best_estimator_) \n",
    "print(\"R2:\",clf.best_score_)\n",
    "\n",
    "RMSE = GridSearchCV(GradientBoostingRegressor(random_state=1), \n",
    "                   param_grid = param_grid, scoring='neg_mean_squared_error', \n",
    "                   cv=cv).fit(x_train_scaled, y_train)\n",
    "print(RMSE.best_estimator_) \n",
    "print(\"RMSE:\",RMSE.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
